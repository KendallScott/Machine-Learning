{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/Machine-Learning/blob/main/SVM%20and%20LR/forestCoverLogReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfc8062",
      "metadata": {
        "id": "dcfc8062"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics as mt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fae3751",
      "metadata": {
        "id": "3fae3751",
        "outputId": "a4c3ec2e-581e-4475-ffb9-3fc67641e4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  Wilderness_Area1  Wilderness_Area2  \\\n",
              "0                                6279                 1                 0   \n",
              "1                                6225                 1                 0   \n",
              "2                                6121                 1                 0   \n",
              "3                                6211                 1                 0   \n",
              "4                                6172                 1                 0   \n",
              "\n",
              "   Wilderness_Area3  Wilderness_Area4  Soil_Type1  Soil_Type2  Soil_Type3  \\\n",
              "0                 0                 0           0           0           0   \n",
              "1                 0                 0           0           0           0   \n",
              "2                 0                 0           0           0           0   \n",
              "3                 0                 0           0           0           0   \n",
              "4                 0                 0           0           0           0   \n",
              "\n",
              "   Soil_Type4  Soil_Type5  Soil_Type6  Soil_Type7  Soil_Type8  Soil_Type9  \\\n",
              "0           0           0           0           0           0           0   \n",
              "1           0           0           0           0           0           0   \n",
              "2           0           0           0           0           0           0   \n",
              "3           0           0           0           0           0           0   \n",
              "4           0           0           0           0           0           0   \n",
              "\n",
              "   Soil_Type10  Soil_Type11  Soil_Type12  Soil_Type13  Soil_Type14  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            1            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type15  Soil_Type16  Soil_Type17  Soil_Type18  Soil_Type19  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type20  Soil_Type21  Soil_Type22  Soil_Type23  Soil_Type24  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type25  Soil_Type26  Soil_Type27  Soil_Type28  Soil_Type29  \\\n",
              "0            0            0            0            0            1   \n",
              "1            0            0            0            0            1   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            1   \n",
              "\n",
              "   Soil_Type30  Soil_Type31  Soil_Type32  Soil_Type33  Soil_Type34  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            1            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type40  Cover_Type  \n",
              "0            0           5  \n",
              "1            0           5  \n",
              "2            0           2  \n",
              "3            0           2  \n",
              "4            0           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49dbea95-5023-4aab-a916-93e1b414491e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49dbea95-5023-4aab-a916-93e1b414491e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49dbea95-5023-4aab-a916-93e1b414491e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49dbea95-5023-4aab-a916-93e1b414491e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Reading and cleaning the data\n",
        "# forest_cover_type = files.upload()\n",
        "\n",
        "forest_cover_type = pd.read_csv(\"covtype.csv\")\n",
        "forest_cover_type.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88eb87d2",
      "metadata": {
        "id": "88eb87d2",
        "outputId": "a3dbb8d4-9082-4f51-c9b4-dd404a76da4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  Rawah  Neota  Comanche Peak  \\\n",
              "0                                6279      1      0              0   \n",
              "1                                6225      1      0              0   \n",
              "2                                6121      1      0              0   \n",
              "3                                6211      1      0              0   \n",
              "4                                6172      1      0              0   \n",
              "\n",
              "   Cache la Poudre  Soil_Type1  Soil_Type2  Soil_Type3  Soil_Type4  \\\n",
              "0                0           0           0           0           0   \n",
              "1                0           0           0           0           0   \n",
              "2                0           0           0           0           0   \n",
              "3                0           0           0           0           0   \n",
              "4                0           0           0           0           0   \n",
              "\n",
              "   Soil_Type5  Soil_Type6  Soil_Type7  Soil_Type8  Soil_Type9  Soil_Type10  \\\n",
              "0           0           0           0           0           0            0   \n",
              "1           0           0           0           0           0            0   \n",
              "2           0           0           0           0           0            0   \n",
              "3           0           0           0           0           0            0   \n",
              "4           0           0           0           0           0            0   \n",
              "\n",
              "   Soil_Type11  Soil_Type12  Soil_Type13  Soil_Type14  Soil_Type15  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            1            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type16  Soil_Type17  Soil_Type18  Soil_Type19  Soil_Type20  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type21  Soil_Type22  Soil_Type23  Soil_Type24  Soil_Type25  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type26  Soil_Type27  Soil_Type28  Soil_Type29  Soil_Type30  \\\n",
              "0            0            0            0            1            0   \n",
              "1            0            0            0            1            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            1   \n",
              "4            0            0            0            1            0   \n",
              "\n",
              "   Soil_Type31  Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0            0            0            0            0            0           5  \n",
              "1            0            0            0            0            0           5  \n",
              "2            0            0            0            0            0           2  \n",
              "3            0            0            0            0            0           2  \n",
              "4            0            0            0            0            0           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efad119c-55d6-4d21-a64a-fc224fa7e308\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Rawah</th>\n",
              "      <th>Neota</th>\n",
              "      <th>Comanche Peak</th>\n",
              "      <th>Cache la Poudre</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efad119c-55d6-4d21-a64a-fc224fa7e308')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efad119c-55d6-4d21-a64a-fc224fa7e308 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efad119c-55d6-4d21-a64a-fc224fa7e308');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Renaming wilderness areas\n",
        "forest_cover_type.rename(columns={'Wilderness_Area1':'Rawah','Wilderness_Area2':'Neota','Wilderness_Area3':'Comanche Peak','Wilderness_Area4':'Cache la Poudre'},inplace=True)\n",
        "forest_cover_type.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05e33e1",
      "metadata": {
        "id": "b05e33e1"
      },
      "outputs": [],
      "source": [
        "#The code below is used to turn categorical variables into individual columns (how the data was when we downloaded it) I kept it here for now for reference or if we change datasets\n",
        "\n",
        "#tmpSoil = pd.get_dummies(forest_cover_type.Soil_Type,prefix='Soil')\n",
        "#forest_cover_type = pd.concat((forest_cover_type,tmpSoil),axis=1)\n",
        "#tmpWild = pd.get_dummies(forest_cover_type.Wilderness_Area,prefix='Area')\n",
        "#forest_cover_type = pd.concat((forest_cover_type,tmpWild),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72389e27",
      "metadata": {
        "id": "72389e27"
      },
      "outputs": [],
      "source": [
        "# Creating a new dataset that only contains the most common cover types\n",
        "forestDF = forest_cover_type[(forest_cover_type['Cover_Type']==1) | (forest_cover_type['Cover_Type']==2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf69cbb",
      "metadata": {
        "id": "dbf69cbb"
      },
      "source": [
        "#### Renaming cover type to actual names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b489265",
      "metadata": {
        "id": "1b489265"
      },
      "source": [
        "We could skip the next couple steps and just leave cover type as 1 and 2 and everything should work. Left it like this for workflow/reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc32606c",
      "metadata": {
        "id": "cc32606c",
        "outputId": "74e7af04-1ff3-4adf-9315-87b8eda170c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count             495141\n",
              "unique                 2\n",
              "top       Lodgepole Pine\n",
              "freq              283301\n",
              "Name: Cover_Type, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# this isnt necessary but maybe helpful for plotting or seeing which cover types are use\n",
        "forestDF = forestDF.astype({'Cover_Type':'string'})\n",
        "forestDF['Cover_Type'] = forestDF['Cover_Type'].str.replace('1','Spruce/Fir')\n",
        "forestDF['Cover_Type'] = forestDF['Cover_Type'].str.replace('2','Lodgepole Pine')\n",
        "forestDF['Cover_Type'].describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f513a8e",
      "metadata": {
        "id": "4f513a8e"
      },
      "outputs": [],
      "source": [
        "# Coding Lodgepole Pine as 1 and Spruce/Fir as 0\n",
        "\n",
        "# Lodgepole Pine = 1 | Spruce/Fir = 0\n",
        "forestDF['treeType'] = forestDF.Cover_Type=='Lodgepole Pine'\n",
        "forestDF.treeType = forestDF.treeType.astype(np.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Models\n",
        "\n",
        "We decided to compare 2 different logistic regression tactics, in order to determine what model worked best to predict Cover Type.\n",
        "\n",
        "For our first model, we decided to look at the most prominent cover types only (Spruce/Fir and Lodgepole Pine). \n",
        "\n",
        "The other model predicted all cover types, and was included in our intial analysis of this dataset. \n",
        "\n",
        "After comparing the results, we will make a recommendation for which model to implement in order to predict Cover Type."
      ],
      "metadata": {
        "id": "8zN4Z9ULBc-c"
      },
      "id": "8zN4Z9ULBc-c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Create Models 50\n",
        "\n",
        "Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
      ],
      "metadata": {
        "id": "gg2dVWM5hsJp"
      },
      "id": "gg2dVWM5hsJp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "524b07ed",
      "metadata": {
        "id": "524b07ed"
      },
      "outputs": [],
      "source": [
        "# Deleting original cover type column\n",
        "if 'Cover_Type' in forestDF:\n",
        "    del forestDF['Cover_Type']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd81bde",
      "metadata": {
        "id": "7bd81bde"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11bb0b87",
      "metadata": {
        "id": "11bb0b87"
      },
      "outputs": [],
      "source": [
        "# Splitting the data between response and predictors\n",
        "if 'treeType' in forestDF:\n",
        "    Y = forestDF['treeType'].values\n",
        "    X = forestDF.values\n",
        "\n",
        "    X.drop(['treeType'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d276d2",
      "metadata": {
        "id": "68d276d2",
        "outputId": "91dc3d7d-894c-49e3-ae9d-09f5308d71e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ShuffleSplit(n_splits=10, random_state=None, test_size=0.2, train_size=None)\n"
          ]
        }
      ],
      "source": [
        "#Creating cross validation object\n",
        "num_cv_iter = 10\n",
        "num_instances = len(Y)\n",
        "cv_object = ShuffleSplit(n_splits=num_cv_iter,test_size=0.2)\n",
        "print(cv_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eadf2078",
      "metadata": {
        "id": "eadf2078"
      },
      "outputs": [],
      "source": [
        "# Creating logistic regression object\n",
        "lr_clf = LogisticRegression(penalty='l2',C=1.0,class_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aab106f",
      "metadata": {
        "id": "9aab106f",
        "outputId": "d127d1c9-fc61-4e36-8672-d00ee720dcf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 0 ****\n",
            "Accuracy 0.7578285148794798\n",
            "Confusion Matrix \n",
            " [[29426 12785]\n",
            " [11197 45621]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 1 ****\n",
            "Accuracy 0.7557988064102434\n",
            "Confusion Matrix \n",
            " [[29384 12932]\n",
            " [11251 45462]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 2 ****\n",
            "Accuracy 0.7589796928172555\n",
            "Confusion Matrix \n",
            " [[29532 12886]\n",
            " [10982 45629]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 3 ****\n",
            "Accuracy 0.7573539064314494\n",
            "Confusion Matrix \n",
            " [[29554 12830]\n",
            " [11199 45446]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 4 ****\n",
            "Accuracy 0.7528097829928607\n",
            "Confusion Matrix \n",
            " [[30523 12017]\n",
            " [12462 44027]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 5 ****\n",
            "Accuracy 0.7529006654616325\n",
            "Confusion Matrix \n",
            " [[29729 12675]\n",
            " [11795 44830]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 6 ****\n",
            "Accuracy 0.7577578285148795\n",
            "Confusion Matrix \n",
            " [[29519 13060]\n",
            " [10929 45521]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 7 ****\n",
            "Accuracy 0.7432671237718245\n",
            "Confusion Matrix \n",
            " [[28700 13743]\n",
            " [11681 44905]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 8 ****\n",
            "Accuracy 0.7488210524189883\n",
            "Confusion Matrix \n",
            " [[29032 13540]\n",
            " [11334 45123]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 9 ****\n",
            "Accuracy 0.7450342828868312\n",
            "Confusion Matrix \n",
            " [[28640 13747]\n",
            " [11502 45140]]\n"
          ]
        }
      ],
      "source": [
        "#Running logistic regression on 10 random test/train splits\n",
        "iter_num = 0\n",
        "\n",
        "for iter_num, (train_indices,test_indices) in enumerate(cv_object.split(X,Y)):\n",
        "    lr_clf.fit(X[train_indices],Y[train_indices])\n",
        "    y_hat = lr_clf.predict(X[test_indices])\n",
        "    \n",
        "    print('****Iteration',iter_num,'****')\n",
        "    print('Accuracy',mt.accuracy_score(Y[test_indices],y_hat))\n",
        "    print('Confusion Matrix \\n',mt.confusion_matrix(Y[test_indices],y_hat))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(lr_clf, X, y=Y, cv=cv_object) # this also can help with parallelism\n",
        "print(accuracies)"
      ],
      "metadata": {
        "id": "RlhBbYVJ3yoZ",
        "outputId": "2f124aa5-12ad-415c-834e-ea4588e763d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RlhBbYVJ3yoZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.76127195 0.76093871 0.74822527 0.76087813 0.75709136 0.7558089\n",
            " 0.75095174 0.75796989 0.75779822 0.75564734]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://realpython.com/logistic-regression-python/#logistic-regression-in-python\n",
        "forest_cover_type_copy = pd.read_csv('covtype.csv') \n",
        "\n",
        "# subset df to make binary categorical\n",
        "# second number not inclusive\n",
        "Wilderness_Area = forest_cover_type_copy.iloc[:, 10:14]\n",
        "Wilderness_Area['Wilderness_Area'] = Wilderness_Area.idxmax(axis = 1)\n",
        "\n",
        "# subset df to make binary categorical\n",
        "# second number not inclusive\n",
        "Soil_Type = forest_cover_type_copy.iloc[:, 14:54]\n",
        "Soil_Type['Soil_Type'] = Soil_Type.idxmax(axis = 1)\n",
        "\n",
        "# only keep the new column\n",
        "Soil_Type = Soil_Type[['Soil_Type']]\n",
        "Wilderness_Area = Wilderness_Area[['Wilderness_Area']]\n",
        "\n",
        "# Add new columns to df\n",
        "forest_cover_type_copy['Soil_Type'] = Soil_Type\n",
        "forest_cover_type_copy['Wilderness_Area'] = Wilderness_Area\n",
        "\n",
        "# delete first few characters in column so we only have number\n",
        "forest_cover_type_copy['Soil_Type'] = forest_cover_type_copy['Soil_Type'].str[9:]\n",
        "forest_cover_type_copy['Wilderness_Area'] = forest_cover_type_copy['Wilderness_Area'].str[15:]\n",
        "\n",
        "# delete superfluous columns now that new columsn are added\n",
        "forest_cover_type_copy.drop(forest_cover_type_copy.iloc[:, 10:54], \n",
        "                       axis = 1, \n",
        "                       inplace = True)\n",
        "\n",
        "# Assign specific features to two different variables\n",
        "X = forest_cover_type_copy.iloc[:, 0:12]\n",
        "y = forest_cover_type_copy.iloc[:, 12]"
      ],
      "metadata": {
        "id": "o5L_XtgOA-vL"
      },
      "id": "o5L_XtgOA-vL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://realpython.com/logistic-regression-python/#logistic-regression-in-python\n",
        "\n",
        "# Assign specific features to two different variables\n",
        "X = forest_cover_type_copy.drop(['Cover_Type'], axis=1)\n",
        "y = forest_cover_type_copy['Cover_Type']\n",
        "# Build a logistic regression model\n",
        "model = LogisticRegression(solver = 'liblinear', random_state = 0)\n",
        "model = model.fit(X, y)"
      ],
      "metadata": {
        "id": "B4vmUZ92BGrG"
      },
      "id": "B4vmUZ92BGrG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classes_\n",
        "# See the model results\n",
        "print(model.predict_proba(X), '\\n')\n",
        "print(model.predict(X), '\\n')\n",
        "\n",
        "print('The model score is ', model.score(X, y), '\\n')\n",
        "\n",
        "print(classification_report(y, model.predict(X)), '\\n')"
      ],
      "metadata": {
        "id": "Zf-ZYw-nBKuB"
      },
      "id": "Zf-ZYw-nBKuB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y, model.predict(X)), '\\n')\n",
        "\n",
        "cm = confusion_matrix(y, model.predict(X))\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8, 8))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks = (0, 1, 2, 3, 4, 5, 6))\n",
        "ax.yaxis.set(ticks = (0, 1, 2, 3, 4, 5, 6))\n",
        "ax.set_ylim(6.5, -0.5)\n",
        "for i in range(7):\n",
        "    for j in range(7):\n",
        "        ax.text(j, \n",
        "                i, \n",
        "                cm[i, j], \n",
        "                ha = 'center', \n",
        "                va = 'center', \n",
        "                color = 'Green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JYS7JjOEBO0i"
      },
      "id": "JYS7JjOEBO0i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the metrics used to evaluate the model\n",
        "print(classification_report(y, model.predict(X)))"
      ],
      "metadata": {
        "id": "HLlIb2G5BVO9"
      },
      "id": "HLlIb2G5BVO9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model with higher C value. default was c = 1\n",
        "\n",
        "\n",
        "model = LogisticRegression(solver = 'liblinear', \n",
        "                           C = 10.0, \n",
        "                           random_state = 0)\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "print('The model score is ', model.score(X, y), '\\n')\n",
        "\n",
        "# print the metrics used to evaluate the model\n",
        "print(classification_report(y, model.predict(X)))"
      ],
      "metadata": {
        "id": "mlPVMpNzBZhe"
      },
      "id": "mlPVMpNzBZhe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Advantages 10\n",
        "Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
      ],
      "metadata": {
        "id": "ZDkhl8Y-h3f_"
      },
      "id": "ZDkhl8Y-h3f_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpret Feature Importance 30\n",
        "\n",
        "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
      ],
      "metadata": {
        "id": "5M-XYvRzh_Id"
      },
      "id": "5M-XYvRzh_Id"
    },
    {
      "cell_type": "markdown",
      "id": "a558f61e",
      "metadata": {
        "id": "a558f61e"
      },
      "source": [
        "## Looking at weights of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f74ab89",
      "metadata": {
        "id": "7f74ab89",
        "outputId": "379b37fe-cb0d-49c1-87f7-8ef64dd01916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elevation has weight of -0.007469660605667776\n",
            "Aspect has weight of 0.0026619881711852423\n",
            "Slope has weight of 0.07385207594164944\n",
            "Horizontal_Distance_To_Hydrology has weight of 0.00181736729230246\n",
            "Vertical_Distance_To_Hydrology has weight of 0.0013585870892477247\n",
            "Horizontal_Distance_To_Roadways has weight of 3.1027369921502094e-05\n",
            "Hillshade_9am has weight of 0.06272073482889796\n",
            "Hillshade_Noon has weight of 0.013983990524742407\n",
            "Hillshade_3pm has weight of 0.02986803538881852\n",
            "Horizontal_Distance_To_Fire_Points has weight of 4.16978466766415e-05\n",
            "Rawah has weight of -1.7174495388158607e-05\n",
            "Neota has weight of -0.00041589167188201643\n",
            "Comanche Peak has weight of 0.0011660941695558168\n",
            "Cache la Poudre has weight of 9.661121969107455e-05\n",
            "Soil_Type1 has weight of 0.0\n",
            "Soil_Type2 has weight of 2.1795563995825815e-05\n",
            "Soil_Type3 has weight of 3.0253830603027533e-05\n",
            "Soil_Type4 has weight of 7.745620540800164e-05\n",
            "Soil_Type5 has weight of 0.0\n",
            "Soil_Type6 has weight of 2.0591968854659786e-05\n",
            "Soil_Type7 has weight of 5.911757720694502e-06\n",
            "Soil_Type8 has weight of 3.70514440391652e-07\n",
            "Soil_Type9 has weight of -8.011866523487365e-06\n",
            "Soil_Type10 has weight of 0.0005155215828185174\n",
            "Soil_Type11 has weight of 0.0002682554236101933\n",
            "Soil_Type12 has weight of 0.0007063467596842549\n",
            "Soil_Type13 has weight of 0.0005869764401889833\n",
            "Soil_Type14 has weight of 0.0\n",
            "Soil_Type15 has weight of 0.0\n",
            "Soil_Type16 has weight of 8.420017408391743e-08\n",
            "Soil_Type17 has weight of -1.189993313941574e-06\n",
            "Soil_Type18 has weight of 1.798944333256971e-05\n",
            "Soil_Type19 has weight of -0.00013439492320805663\n",
            "Soil_Type20 has weight of -0.0001938361344676429\n",
            "Soil_Type21 has weight of -8.917350960523644e-05\n",
            "Soil_Type22 has weight of -0.001559977294528256\n",
            "Soil_Type23 has weight of -0.0020209254866123544\n",
            "Soil_Type24 has weight of 0.000345831760261258\n",
            "Soil_Type25 has weight of 2.839666889382772e-05\n",
            "Soil_Type26 has weight of 6.404499002456574e-05\n",
            "Soil_Type27 has weight of -4.256653748549289e-05\n",
            "Soil_Type28 has weight of 5.725006604037602e-05\n",
            "Soil_Type29 has weight of 0.0016175970411591275\n",
            "Soil_Type30 has weight of 0.0005888210927656166\n",
            "Soil_Type31 has weight of 2.3200002460434337e-05\n",
            "Soil_Type32 has weight of 0.000392400347758174\n",
            "Soil_Type33 has weight of 0.0006690390069425705\n",
            "Soil_Type34 has weight of 5.962141166225237e-05\n",
            "Soil_Type35 has weight of -5.080942199933251e-05\n",
            "Soil_Type36 has weight of 1.7109855950631365e-06\n",
            "Soil_Type37 has weight of 0.0\n",
            "Soil_Type38 has weight of -0.0005008466829913016\n",
            "Soil_Type39 has weight of -0.0004104094692917353\n",
            "Soil_Type40 has weight of -0.000257686522391227\n"
          ]
        }
      ],
      "source": [
        "weights = lr_clf.coef_.T\n",
        "varNames = forestDF.columns\n",
        "for coef, name in zip(weights,varNames):\n",
        "    print(name,'has weight of',coef[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0868f669",
      "metadata": {
        "id": "0868f669"
      },
      "source": [
        "### Scaling the weights for interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62176a55",
      "metadata": {
        "id": "62176a55",
        "outputId": "a754f24b-32e6-4d35-89e1-f7e364f55d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7748538306960587\n",
            "[[30315 12072]\n",
            " [10224 46418]]\n",
            "Elevation has weight of -1.680031013060939\n",
            "Hillshade_3pm has weight of -0.41619141664762993\n",
            "Soil_Type22 has weight of -0.21371163899772097\n",
            "Soil_Type39 has weight of -0.19856255874372372\n",
            "Soil_Type23 has weight of -0.1789062365919632\n",
            "Hillshade_9am has weight of -0.14383938245882208\n",
            "Soil_Type21 has weight of -0.13889183496017946\n",
            "Soil_Type38 has weight of -0.11983712992580287\n",
            "Soil_Type20 has weight of -0.09930900630989431\n",
            "Soil_Type35 has weight of -0.08983688042243221\n",
            "Soil_Type9 has weight of -0.08873261330003074\n",
            "Soil_Type40 has weight of -0.08372378701524485\n",
            "Comanche Peak has weight of -0.08048999198753475\n",
            "Horizontal_Distance_To_Fire_Points has weight of -0.0569977528617918\n",
            "Rawah has weight of -0.047823021406965975\n",
            "Soil_Type19 has weight of -0.04475845556519341\n",
            "Soil_Type16 has weight of -0.03531924671240271\n",
            "Soil_Type17 has weight of -0.024697010198159987\n",
            "Soil_Type27 has weight of -0.010853131350259702\n",
            "Soil_Type24 has weight of -0.009050798119276051\n",
            "Soil_Type18 has weight of -0.0024936063997200624\n",
            "Soil_Type8 has weight of -0.0018540164036164497\n",
            "Soil_Type1 has weight of 0.0\n",
            "Soil_Type14 has weight of 0.0\n",
            "Soil_Type15 has weight of 0.0\n",
            "Soil_Type37 has weight of 0.0\n",
            "Soil_Type5 has weight of 0.0\n",
            "Soil_Type10 has weight of 0.004729382437646095\n",
            "Aspect has weight of 0.018730452923314187\n",
            "Soil_Type36 has weight of 0.019100035153243627\n",
            "Soil_Type31 has weight of 0.02295952133416209\n",
            "Soil_Type4 has weight of 0.027174265706278063\n",
            "Soil_Type33 has weight of 0.027473704299543687\n",
            "Soil_Type11 has weight of 0.03609012166526241\n",
            "Soil_Type25 has weight of 0.036967679165762456\n",
            "Soil_Type28 has weight of 0.03762150865811783\n",
            "Soil_Type26 has weight of 0.051273349729292136\n",
            "Soil_Type30 has weight of 0.057640418187033776\n",
            "Vertical_Distance_To_Hydrology has weight of 0.05914622804974338\n",
            "Soil_Type29 has weight of 0.07554206853885091\n",
            "Soil_Type6 has weight of 0.0767575812439961\n",
            "Soil_Type13 has weight of 0.08587457733377908\n",
            "Soil_Type7 has weight of 0.10435026943829369\n",
            "Soil_Type34 has weight of 0.11204011626766558\n",
            "Slope has weight of 0.11810446520303947\n",
            "Soil_Type12 has weight of 0.12415295546991112\n",
            "Horizontal_Distance_To_Roadways has weight of 0.15033232610454456\n",
            "Soil_Type32 has weight of 0.16897880182243583\n",
            "Neota has weight of 0.17825652584724846\n",
            "Soil_Type2 has weight of 0.19145720832096141\n",
            "Soil_Type3 has weight of 0.21717184026718106\n",
            "Cache la Poudre has weight of 0.29289304128964644\n",
            "Horizontal_Distance_To_Hydrology has weight of 0.4171170496235504\n",
            "Hillshade_Noon has weight of 0.6443924711118028\n"
          ]
        }
      ],
      "source": [
        "sclObj = StandardScaler()\n",
        "sclObj.fit(X[train_indices])\n",
        "\n",
        "X_trainScaled = sclObj.transform(X[train_indices])\n",
        "x_testScaled = sclObj.transform(X[test_indices])\n",
        "\n",
        "lrs_clf = LogisticRegression(penalty='l2',C=0.05)\n",
        "lrs_clf.fit(X_trainScaled,Y[train_indices])\n",
        "\n",
        "y_hatS = lrs_clf.predict(x_testScaled)\n",
        "\n",
        "acc = mt.accuracy_score(Y[test_indices],y_hatS)\n",
        "conf = mt.confusion_matrix(Y[test_indices],y_hatS)\n",
        "print('accuracy:',acc)\n",
        "print(conf)\n",
        "\n",
        "zipVars = zip(lrs_clf.coef_.T,forestDF.columns)\n",
        "zipVars = sorted(zipVars)\n",
        "\n",
        "for coef, name in zipVars:\n",
        "    print(name,'has weight of', coef[0])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Soil_Type22' in forestDF:\n",
        "    del forestDF['Soil_Type22']\n",
        "\n",
        "    df = df[cols_of_interest]"
      ],
      "metadata": {
        "id": "bBS0BnJpi7SH"
      },
      "id": "bBS0BnJpi7SH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fab1b855",
      "metadata": {
        "id": "fab1b855"
      },
      "source": [
        "### Plotting weights because probably useful (scaled weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612c25d6",
      "metadata": {
        "id": "612c25d6",
        "outputId": "504561f0-4da9-453f-ead8-92e2545d3b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "weights = pd.Series(lrs_clf.coef_[0],index=forestDF.columns)\n",
        "weights.plot(kind='bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d95ecb9e",
      "metadata": {
        "id": "d95ecb9e"
      },
      "source": [
        "### after this in the notebook i was following he goes over stuff to remove related variables to help with overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49c6293",
      "metadata": {
        "id": "e49c6293"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f16474f",
      "metadata": {
        "id": "6f16474f"
      },
      "source": [
        "### Creating and running the SVM using the scaled and split sets from earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpret Support Vectors(10)\n",
        "\n",
        "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model then analyze the support vectors from the subsampled dataset."
      ],
      "metadata": {
        "id": "IeTkwGHYiUyW"
      },
      "id": "IeTkwGHYiUyW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffcba57",
      "metadata": {
        "id": "2ffcba57"
      },
      "outputs": [],
      "source": [
        "##SVM\n",
        "\n",
        "for train_indices, test_indices in cv_object.split(X,Y): \n",
        "    # I will create new variables here so that it is more obvious what \n",
        "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
        "    # but it makes this code less readable)\n",
        "    X_train = X[train_indices]\n",
        "    y_train = Y[train_indices]\n",
        "    \n",
        "    X_test = X[test_indices]\n",
        "    y_test = Y[test_indices]\n",
        "\n",
        "X_train_scaled = sclObj.transform(X_train) # apply to training\n",
        "X_test_scaled = sclObj.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets investigate SVMs on the data and play with the parameters and kernels\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# train the model just as before\n",
        "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
        "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
        "\n",
        "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
        "\n",
        "acc = mt.accuracy_score(y_test,y_hat)\n",
        "conf = mt.confusion_matrix(y_test,y_hat)\n",
        "print('accuracy:', acc )\n",
        "print(conf)"
      ],
      "metadata": {
        "id": "xPxkd8s-HT_P"
      },
      "id": "xPxkd8s-HT_P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "below here isn't yet working, but pulls from example notebook for how to interpret the support vector (like he mentioned in class)"
      ],
      "metadata": {
        "id": "1hd1rNLFici4"
      },
      "id": "1hd1rNLFici4"
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets see the statistics of these attributes\n",
        "from pandas.plotting import boxplot\n",
        "\n",
        "# group the original data and the support vectors\n",
        "df_grouped_support = forest_cover_type.groupby(['Cover_Type'])\n",
        "df_grouped = forest_cover_type.groupby(['Cover_Type'])\n",
        "\n",
        "# plot KDE of Different variables\n",
        "vars_to_plot = ['Age','Pclass','IsMale','FamilySize']\n",
        "\n",
        "for v in vars_to_plot:\n",
        "    plt.figure(figsize=(10,4))\n",
        "    # plot support vector stats\n",
        "    plt.subplot(1,2,1)\n",
        "    ax = df_grouped_support[v].plot.kde() \n",
        "    plt.legend(['Perished','Survived'])\n",
        "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
        "    \n",
        "    # plot original distributions\n",
        "    plt.subplot(1,2,2)\n",
        "    ax = df_grouped[v].plot.kde() \n",
        "    plt.legend(['Perished','Survived'])\n",
        "    plt.title(v+' (Original)')"
      ],
      "metadata": {
        "id": "zHA-KLY0ga-f"
      },
      "id": "zHA-KLY0ga-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
        "\n",
        "# now lets look at the support for the vectors and see if we they are indicative of anything\n",
        "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
        "\n",
        "# make a dataframe of the training data\n",
        "df_tested_on = df_imputed.iloc[train_indices].copy() # saved from above, the indices chosen for training\n",
        "# now get the support vectors from the trained model\n",
        "df_support = df_tested_on.iloc[svm_clf.support_,:].copy()\n",
        "\n",
        "df_support['Survived'] = y[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
        "df_imputed['Survived'] = y # also add it back in for the original data\n",
        "df_support.info()"
      ],
      "metadata": {
        "id": "DAURr5CDgeza"
      },
      "id": "DAURr5CDgeza",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}