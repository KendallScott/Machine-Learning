{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KendallScott/Machine-Learning/blob/main/Copy_of_forestCoverLogReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contributors\n",
        "* Tadd Backus\n",
        "* Kendall Scott\n",
        "* Austin Webb\n",
        "* Milan Patel\n"
      ],
      "metadata": {
        "id": "e6TGIIukk6c-"
      },
      "id": "e6TGIIukk6c-"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "HTML('''<script>\n",
        "code_show_err=false; \n",
        "function code_toggle_err() {\n",
        " if (code_show_err){\n",
        " $('div.output_stderr').hide();\n",
        " } else {\n",
        " $('div.output_stderr').show();\n",
        " }\n",
        " code_show_err = !code_show_err\n",
        "} \n",
        "$( document ).ready(code_toggle_err);\n",
        "</script>\n",
        "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
      ],
      "metadata": {
        "id": "GUBk6wGhk3v8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c51540f9-b2ac-4cf1-af1f-5af499158945"
      },
      "id": "GUBk6wGhk3v8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>\n",
              "code_show_err=false; \n",
              "function code_toggle_err() {\n",
              " if (code_show_err){\n",
              " $('div.output_stderr').hide();\n",
              " } else {\n",
              " $('div.output_stderr').show();\n",
              " }\n",
              " code_show_err = !code_show_err\n",
              "} \n",
              "$( document ).ready(code_toggle_err);\n",
              "</script>\n",
              "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dcfc8062",
      "metadata": {
        "id": "dcfc8062"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics as mt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "3fae3751",
      "metadata": {
        "id": "3fae3751",
        "outputId": "c9427f91-9803-4054-e7cb-ab497fce92ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-b2213be2f756>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Wilderness_Area['Wilderness_Area'] = Wilderness_Area.idxmax(axis = 1)\n",
            "<ipython-input-46-b2213be2f756>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Soil_Type['Soil_Type'] = Soil_Type.idxmax(axis = 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  Cover_Type Soil_Type Wilderness_Area  \n",
              "0                                6279           5        29               1  \n",
              "1                                6225           5        29               1  \n",
              "2                                6121           2        12               1  \n",
              "3                                6211           2        30               1  \n",
              "4                                6172           5        29               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b9da17b-2744-415f-9fa6-1ebbbdfe1044\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Cover_Type</th>\n",
              "      <th>Soil_Type</th>\n",
              "      <th>Wilderness_Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b9da17b-2744-415f-9fa6-1ebbbdfe1044')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b9da17b-2744-415f-9fa6-1ebbbdfe1044 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b9da17b-2744-415f-9fa6-1ebbbdfe1044');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Reading and cleaning the data\n",
        "# forest_cover_type = files.upload()\n",
        "\n",
        "forest_cover_type = pd.read_csv(\"covtype.csv\")\n",
        "# subset df to make binary categorical\n",
        "# second number not inclusive\n",
        "Wilderness_Area = forest_cover_type.iloc[:, 10:14]\n",
        "\n",
        "#\n",
        "Wilderness_Area['Wilderness_Area'] = Wilderness_Area.idxmax(axis = 1)\n",
        "Wilderness_Area\n",
        "\n",
        "\n",
        "# subset df to make binary categorical\n",
        "# second number not inclusive\n",
        "Soil_Type = forest_cover_type.iloc[:, 14:54]\n",
        "\n",
        "#\n",
        "Soil_Type['Soil_Type'] = Soil_Type.idxmax(axis = 1)\n",
        "Soil_Type\n",
        "\n",
        "# only keep the new column\n",
        "Soil_Type = Soil_Type[['Soil_Type']]\n",
        "Soil_Type\n",
        "\n",
        "Wilderness_Area = Wilderness_Area[['Wilderness_Area']]\n",
        "Wilderness_Area\n",
        "\n",
        "# Add new columns to df\n",
        "forest_cover_type['Soil_Type'] = Soil_Type\n",
        "forest_cover_type['Wilderness_Area'] = Wilderness_Area\n",
        "\n",
        "# delete first few characters in column so we only have number\n",
        "\n",
        "forest_cover_type['Soil_Type'] = forest_cover_type['Soil_Type'].str[9:]\n",
        "forest_cover_type['Wilderness_Area'] = forest_cover_type['Wilderness_Area'].str[15:]\n",
        "\n",
        "# delete superfluous columns now that new columsn are added\n",
        "forest_cover_type.drop(forest_cover_type.iloc[:, 10:54], \n",
        "                       axis = 1, \n",
        "                       inplace = True)\n",
        "forest_cover_type.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "72389e27",
      "metadata": {
        "id": "72389e27",
        "outputId": "83781555-8dc9-42b9-9d29-c3f820b956c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0            2596      51      3                               258   \n",
              "1            2590      56      2                               212   \n",
              "2            2804     139      9                               268   \n",
              "3            2785     155     18                               242   \n",
              "4            2595      45      2                               153   \n",
              "...           ...     ...    ...                               ...   \n",
              "581007       2396     153     20                                85   \n",
              "581008       2391     152     19                                67   \n",
              "581009       2386     159     17                                60   \n",
              "581010       2384     170     15                                60   \n",
              "581011       2383     165     13                                60   \n",
              "\n",
              "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                                    0                              510   \n",
              "1                                   -6                              390   \n",
              "2                                   65                             3180   \n",
              "3                                  118                             3090   \n",
              "4                                   -1                              391   \n",
              "...                                ...                              ...   \n",
              "581007                              17                              108   \n",
              "581008                              12                               95   \n",
              "581009                               7                               90   \n",
              "581010                               5                               90   \n",
              "581011                               4                               67   \n",
              "\n",
              "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0                 221             232            148   \n",
              "1                 220             235            151   \n",
              "2                 234             238            135   \n",
              "3                 238             238            122   \n",
              "4                 220             234            150   \n",
              "...               ...             ...            ...   \n",
              "581007            240             237            118   \n",
              "581008            240             237            119   \n",
              "581009            236             241            130   \n",
              "581010            230             245            143   \n",
              "581011            231             244            141   \n",
              "\n",
              "        Horizontal_Distance_To_Fire_Points  Cover_Type Soil_Type  \\\n",
              "0                                     6279           5        29   \n",
              "1                                     6225           5        29   \n",
              "2                                     6121           2        12   \n",
              "3                                     6211           2        30   \n",
              "4                                     6172           5        29   \n",
              "...                                    ...         ...       ...   \n",
              "581007                                 837           3         2   \n",
              "581008                                 845           3         2   \n",
              "581009                                 854           3         2   \n",
              "581010                                 864           3         2   \n",
              "581011                                 875           3         2   \n",
              "\n",
              "       Wilderness_Area  \n",
              "0                    1  \n",
              "1                    1  \n",
              "2                    1  \n",
              "3                    1  \n",
              "4                    1  \n",
              "...                ...  \n",
              "581007               3  \n",
              "581008               3  \n",
              "581009               3  \n",
              "581010               3  \n",
              "581011               3  \n",
              "\n",
              "[581012 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b069bbfd-4355-4a1b-873c-1cb09171c70f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Cover_Type</th>\n",
              "      <th>Soil_Type</th>\n",
              "      <th>Wilderness_Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581007</th>\n",
              "      <td>2396</td>\n",
              "      <td>153</td>\n",
              "      <td>20</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>108</td>\n",
              "      <td>240</td>\n",
              "      <td>237</td>\n",
              "      <td>118</td>\n",
              "      <td>837</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581008</th>\n",
              "      <td>2391</td>\n",
              "      <td>152</td>\n",
              "      <td>19</td>\n",
              "      <td>67</td>\n",
              "      <td>12</td>\n",
              "      <td>95</td>\n",
              "      <td>240</td>\n",
              "      <td>237</td>\n",
              "      <td>119</td>\n",
              "      <td>845</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581009</th>\n",
              "      <td>2386</td>\n",
              "      <td>159</td>\n",
              "      <td>17</td>\n",
              "      <td>60</td>\n",
              "      <td>7</td>\n",
              "      <td>90</td>\n",
              "      <td>236</td>\n",
              "      <td>241</td>\n",
              "      <td>130</td>\n",
              "      <td>854</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581010</th>\n",
              "      <td>2384</td>\n",
              "      <td>170</td>\n",
              "      <td>15</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>230</td>\n",
              "      <td>245</td>\n",
              "      <td>143</td>\n",
              "      <td>864</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581011</th>\n",
              "      <td>2383</td>\n",
              "      <td>165</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>231</td>\n",
              "      <td>244</td>\n",
              "      <td>141</td>\n",
              "      <td>875</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581012 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b069bbfd-4355-4a1b-873c-1cb09171c70f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b069bbfd-4355-4a1b-873c-1cb09171c70f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b069bbfd-4355-4a1b-873c-1cb09171c70f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Creating a new dataset that only contains the most common cover types\n",
        "#updated to all\n",
        "forestDF = forest_cover_type\n",
        "forestDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf69cbb",
      "metadata": {
        "id": "dbf69cbb"
      },
      "source": [
        "#### Renaming cover type to actual names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Models\n",
        "\n",
        "We decided to compare 2 different logistic regression tactics, in order to determine what model worked best to predict Cover Type.\n",
        "\n",
        "For our first model, we decided to look at the most prominent cover types only (Spruce/Fir and Lodgepole Pine). \n",
        "\n",
        "The other model predicted all cover types, and was included in our intial analysis of this dataset. \n",
        "\n",
        "After comparing the results, we will make a recommendation for which model to implement in order to predict Cover Type."
      ],
      "metadata": {
        "id": "8zN4Z9ULBc-c"
      },
      "id": "8zN4Z9ULBc-c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Create Models 50\n",
        "\n",
        "Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
      ],
      "metadata": {
        "id": "gg2dVWM5hsJp"
      },
      "id": "gg2dVWM5hsJp"
    },
    {
      "cell_type": "markdown",
      "id": "7bd81bde",
      "metadata": {
        "id": "7bd81bde"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the high colinearity between the Hillshade variables, we limited the data down to Hillshade noon only."
      ],
      "metadata": {
        "id": "H4L7EtrwoBZy"
      },
      "id": "H4L7EtrwoBZy"
    },
    {
      "cell_type": "code",
      "source": [
        "simpleStats = forest_cover_type.describe()\n",
        "\n",
        "simpleStats.reset_index(inplace=True)\n",
        "num_col = forest_cover_type._get_numeric_data().columns\n",
        "simpleStats = simpleStats[simpleStats['index'] != 'count']\n",
        "\n",
        "# make list of hillside variables\n",
        "hillside = ['Hillshade_9am','Hillshade_Noon',\n",
        "                        'Hillshade_3pm']\n",
        "hillside_df=simpleStats[hillside]\n",
        "\n",
        "# Correlation df\n",
        "cormat = hillside_df.corr()\n",
        "# Round to two decimals\n",
        "round(cormat, 2)\n",
        "\n",
        "# heatmap of the correlations\n",
        "matrix = np.triu(np.ones_like(cormat, dtype=bool))\n",
        "sns.heatmap(cormat, annot = True, mask = matrix);"
      ],
      "metadata": {
        "id": "rr2FgbhzoAGX",
        "outputId": "f8b378e1-866e-4621-cb84-695facded058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "id": "rr2FgbhzoAGX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forestDF= forestDF.drop(['Hillshade_3pm', 'Hillshade_9am'], axis=1)"
      ],
      "metadata": {
        "id": "oEs8SSBStm9O"
      },
      "id": "oEs8SSBStm9O",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "11bb0b87",
      "metadata": {
        "id": "11bb0b87"
      },
      "outputs": [],
      "source": [
        "# Assign specific features to two different variables\n",
        "if 'Cover_Type' in forestDF:\n",
        "    Y = forestDF['Cover_Type'].values\n",
        "    del forestDF['Cover_Type']\n",
        "    X = forestDF.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "if2GLqrmh_JU",
        "outputId": "a4ca44ce-1427-46a4-dec3-b7d4c98c9eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "if2GLqrmh_JU",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2596, 51, 3, ..., 6279, '29', '1'],\n",
              "       [2590, 56, 2, ..., 6225, '29', '1'],\n",
              "       [2804, 139, 9, ..., 6121, '12', '1'],\n",
              "       ...,\n",
              "       [2386, 159, 17, ..., 854, '2', '3'],\n",
              "       [2384, 170, 15, ..., 864, '2', '3'],\n",
              "       [2383, 165, 13, ..., 875, '2', '3']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "68d276d2",
      "metadata": {
        "id": "68d276d2",
        "outputId": "aef5e6cc-71b2-4f4f-99e4-e306b968c6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ShuffleSplit(n_splits=10, random_state=None, test_size=0.2, train_size=None)\n"
          ]
        }
      ],
      "source": [
        "#Creating cross validation object\n",
        "num_cv_iter = 10\n",
        "num_instances = len(Y)\n",
        "cv_object = ShuffleSplit(n_splits=num_cv_iter,test_size=0.2)\n",
        "print(cv_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "eadf2078",
      "metadata": {
        "id": "eadf2078"
      },
      "outputs": [],
      "source": [
        "# Creating logistic regression object\n",
        "lr_clf = LogisticRegression(penalty='l2',C=1.0,class_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9aab106f",
      "metadata": {
        "id": "9aab106f",
        "outputId": "c22329a7-6266-4485-e74a-0ee37e8577d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 0 ****\n",
            "Accuracy 0.5918005559236853\n",
            "Confusion Matrix \n",
            " [[25127 17336   176     0     0     0    51]\n",
            " [13092 42241   694     0     0     9    32]\n",
            " [  271  5489  1368     0     0    34     0]\n",
            " [    3   514    42     0     0     4     0]\n",
            " [  404  1541    15     0     0     0     0]\n",
            " [  274  2869   367     0     0     8     0]\n",
            " [ 3619   582    16     0     0     0    25]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 1 ****\n",
            "Accuracy 0.5934098086968495\n",
            "Confusion Matrix \n",
            " [[25100 16785   284     0     0     7     1]\n",
            " [13445 42350   802     0     0     8     1]\n",
            " [  320  5491  1495     0     0    33     0]\n",
            " [    4   526    52     0     0     4     0]\n",
            " [  401  1536    13     0     0     0     0]\n",
            " [  275  2724   430     0     0    11     0]\n",
            " [ 3499   587    19     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 2 ****\n",
            "Accuracy 0.5935905269227129\n",
            "Confusion Matrix \n",
            " [[25124 17370   138     0     0     9     2]\n",
            " [13172 42677   622     0     0    28     1]\n",
            " [  325  5539  1154     0     0    77     0]\n",
            " [    2   495    36     0     0     5     0]\n",
            " [  411  1528     5     0     0     0     0]\n",
            " [  272  2779   362     0     0    22     0]\n",
            " [ 3490   557     1     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 3 ****\n",
            "Accuracy 0.5935044706246827\n",
            "Confusion Matrix \n",
            " [[24679 17122   210     0     0     1     6]\n",
            " [13345 42780   717     0     0     6     0]\n",
            " [  298  5385  1505     0     0    27     0]\n",
            " [    2   511    47     0     0     3     0]\n",
            " [  383  1542    10     0     0     0     0]\n",
            " [  296  2678   488     0     0     3     0]\n",
            " [ 3589   563     7     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 4 ****\n",
            "Accuracy 0.5928590483894564\n",
            "Confusion Matrix \n",
            " [[24395 17411   235     0     0     7     0]\n",
            " [13142 43126   667     0     0    14     0]\n",
            " [  296  5492  1364     0     0    36     0]\n",
            " [    1   518    40     0     0     2     0]\n",
            " [  388  1545     9     0     0     0     0]\n",
            " [  272  2758   398     0     0     7     0]\n",
            " [ 3452   621     7     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 5 ****\n",
            "Accuracy 0.5922824711926542\n",
            "Confusion Matrix \n",
            " [[24024 18209   250     0     0     0    10]\n",
            " [12408 43434   640     0     0     2     1]\n",
            " [  296  5481  1367     0     0     4     0]\n",
            " [    2   493    61     0     0     0     0]\n",
            " [  404  1513    11     0     0     0     0]\n",
            " [  270  2817   405     0     0     0     0]\n",
            " [ 3390   696    15     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 6 ****\n",
            "Accuracy 0.5935044706246827\n",
            "Confusion Matrix \n",
            " [[24121 17828   169     0     0     7     6]\n",
            " [12565 43750   614     0     0    14     3]\n",
            " [  282  5800  1075     0     0    56     0]\n",
            " [    1   520    29     0     0     2     0]\n",
            " [  378  1471     8     0     0     0     0]\n",
            " [  268  2893   252     0     0    21     0]\n",
            " [ 3460   608     2     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 7 ****\n",
            "Accuracy 0.5917403165150642\n",
            "Confusion Matrix \n",
            " [[24660 17211   168     0     0     0     0]\n",
            " [13283 42943   547     0     0     2     0]\n",
            " [  333  5718  1156     0     0    17     0]\n",
            " [    2   475    47     0     0     0     0]\n",
            " [  397  1510    14     0     0     0     0]\n",
            " [  320  2920   297     0     0     3     0]\n",
            " [ 3550   622     8     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 8 ****\n",
            "Accuracy 0.5928762596490624\n",
            "Confusion Matrix \n",
            " [[24034 18051   183     0     0     7     0]\n",
            " [12596 43722   587     0     0    13     0]\n",
            " [  282  5685  1125     0     0    26     0]\n",
            " [    2   513    28     0     0     0     0]\n",
            " [  364  1453    11     0     0     0     0]\n",
            " [  219  2930   313     0     0    13     0]\n",
            " [ 3412   632     2     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 9 ****\n",
            "Accuracy 0.5876096142096159\n",
            "Confusion Matrix \n",
            " [[23093 18951    68     0     0     3    28]\n",
            " [12368 44191   260     0     0    18     3]\n",
            " [  293  5787   977     0     0    44     0]\n",
            " [    3   522    33     0     0     1     0]\n",
            " [  389  1519     6     0     0     0     0]\n",
            " [  357  2904   232     0     0    11     0]\n",
            " [ 3338   794     0     0     0     0    10]]\n"
          ]
        }
      ],
      "source": [
        "#Running logistic regression on 10 random test/train splits\n",
        "iter_num = 0\n",
        "\n",
        "for iter_num, (train_indices,test_indices) in enumerate(cv_object.split(X,Y)):\n",
        "    lr_clf.fit(X[train_indices],Y[train_indices])\n",
        "    y_hat = lr_clf.predict(X[test_indices])\n",
        "    \n",
        "    print('****Iteration',iter_num,'****')\n",
        "    print('Accuracy',mt.accuracy_score(Y[test_indices],y_hat))\n",
        "    print('Confusion Matrix \\n',mt.confusion_matrix(Y[test_indices],y_hat))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(lr_clf, X, y=Y, cv=cv_object) # this also can help with parallelism\n",
        "print(accuracies)"
      ],
      "metadata": {
        "id": "RlhBbYVJ3yoZ",
        "outputId": "c61d2544-a8bb-4e77-9de9-f4e6b7f29332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RlhBbYVJ3yoZ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5934012  0.59787613 0.59373682 0.59287626 0.59319467 0.59451133\n",
            " 0.58797966 0.59284184 0.59503627 0.59546655]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to leverage Random Forest to eliminate some of the variables included in the model, to see if there is an increase in performance in a simpler model."
      ],
      "metadata": {
        "id": "ahvN4uSBqoW0"
      },
      "id": "ahvN4uSBqoW0"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# https://realpython.com/logistic-regression-python/#logistic-regression-in-python\n",
        "forest_cover_type_copy = pd.read_csv('covtype.csv') \n",
        "\n",
        "# subset df to make binary categorical\n",
        "# second number not inclusive\n",
        "Wilderness_Area = forest_cover_type_copy.iloc[:, 10:14]\n",
        "Wilderness_Area['Wilderness_Area'] = Wilderness_Area.idxmax(axis = 1)\n",
        "\n",
        "# subset df to make binary categorical\n",
        "# second number not inclusive\n",
        "Soil_Type = forest_cover_type_copy.iloc[:, 14:54]\n",
        "Soil_Type['Soil_Type'] = Soil_Type.idxmax(axis = 1)\n",
        "\n",
        "# only keep the new column\n",
        "Soil_Type = Soil_Type[['Soil_Type']]\n",
        "Wilderness_Area = Wilderness_Area[['Wilderness_Area']]\n",
        "\n",
        "# Add new columns to df\n",
        "forest_cover_type_copy['Soil_Type'] = Soil_Type\n",
        "forest_cover_type_copy['Wilderness_Area'] = Wilderness_Area\n",
        "\n",
        "# delete first few characters in column so we only have number\n",
        "forest_cover_type_copy['Soil_Type'] = forest_cover_type_copy['Soil_Type'].str[9:]\n",
        "forest_cover_type_copy['Wilderness_Area'] = forest_cover_type_copy['Wilderness_Area'].str[15:]\n",
        "\n",
        "# delete superfluous columns now that new columsn are added\n",
        "forest_cover_type_copy.drop(forest_cover_type_copy.iloc[:, 10:54], \n",
        "                       axis = 1, \n",
        "                       inplace = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "FyqT85-PqKGR",
        "outputId": "9e600721-9929-4336-b1df-3c0da2131a6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FyqT85-PqKGR",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-12403de53534>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Wilderness_Area['Wilderness_Area'] = Wilderness_Area.idxmax(axis = 1)\n",
            "<ipython-input-17-12403de53534>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Soil_Type['Soil_Type'] = Soil_Type.idxmax(axis = 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(forest_cover_type_copy.info())"
      ],
      "metadata": {
        "id": "9jnkchWRrv1d",
        "outputId": "57b5291f-5f97-446d-91bf-f0bc9a0c7d45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9jnkchWRrv1d",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 581012 entries, 0 to 581011\n",
            "Data columns (total 13 columns):\n",
            " #   Column                              Non-Null Count   Dtype \n",
            "---  ------                              --------------   ----- \n",
            " 0   Elevation                           581012 non-null  int64 \n",
            " 1   Aspect                              581012 non-null  int64 \n",
            " 2   Slope                               581012 non-null  int64 \n",
            " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64 \n",
            " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64 \n",
            " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64 \n",
            " 6   Hillshade_9am                       581012 non-null  int64 \n",
            " 7   Hillshade_Noon                      581012 non-null  int64 \n",
            " 8   Hillshade_3pm                       581012 non-null  int64 \n",
            " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64 \n",
            " 10  Cover_Type                          581012 non-null  int64 \n",
            " 11  Soil_Type                           581012 non-null  object\n",
            " 12  Wilderness_Area                     581012 non-null  object\n",
            "dtypes: int64(11), object(2)\n",
            "memory usage: 57.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign specific features to two different variables\n",
        "X= forest_cover_type_copy.drop(['Cover_Type'], axis=1)\n",
        "y = forest_cover_type_copy.iloc[:, 10]\n",
        "\n",
        "# Feature Importance Graph\n",
        "# Takes about five minutes\n",
        "rf = RandomForestRegressor(n_estimators = 50)\n",
        "rf.fit(X, y)\n",
        "sort = rf.feature_importances_.argsort()\n",
        "plt.barh(forest_cover_type_copy.columns.values[sort], rf.feature_importances_[sort])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QU5toe0grs3B",
        "outputId": "5844547d-9fd4-4582-c04d-d33b1b86e893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "id": "QU5toe0grs3B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the importance output, we decided to build a simplified model on:\n",
        "\n",
        "*   Elevation\n",
        "*   Horizontal Distance to Fire Points\n",
        "*   Soil Type\n",
        "*   Horizontal Distance to Roadways\n",
        "*   Wilderness Area\n",
        "*   Horizontal Distance To Hydrology\n",
        "*   Hillshade noon\n",
        "*   Aspect\n",
        "*   Slope\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kq5Xrc7wrBHe"
      },
      "id": "Kq5Xrc7wrBHe"
    },
    {
      "cell_type": "code",
      "source": [
        "forestDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pjRm75jKzbCp",
        "outputId": "4a74e8c1-df7b-441b-a995-6eed7daa3969"
      },
      "id": "pjRm75jKzbCp",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0            2596      51      3                               258   \n",
              "1            2590      56      2                               212   \n",
              "2            2804     139      9                               268   \n",
              "3            2785     155     18                               242   \n",
              "4            2595      45      2                               153   \n",
              "...           ...     ...    ...                               ...   \n",
              "581007       2396     153     20                                85   \n",
              "581008       2391     152     19                                67   \n",
              "581009       2386     159     17                                60   \n",
              "581010       2384     170     15                                60   \n",
              "581011       2383     165     13                                60   \n",
              "\n",
              "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                                    0                              510   \n",
              "1                                   -6                              390   \n",
              "2                                   65                             3180   \n",
              "3                                  118                             3090   \n",
              "4                                   -1                              391   \n",
              "...                                ...                              ...   \n",
              "581007                              17                              108   \n",
              "581008                              12                               95   \n",
              "581009                               7                               90   \n",
              "581010                               5                               90   \n",
              "581011                               4                               67   \n",
              "\n",
              "        Hillshade_Noon  Horizontal_Distance_To_Fire_Points Soil_Type  \\\n",
              "0                  232                                6279        29   \n",
              "1                  235                                6225        29   \n",
              "2                  238                                6121        12   \n",
              "3                  238                                6211        30   \n",
              "4                  234                                6172        29   \n",
              "...                ...                                 ...       ...   \n",
              "581007             237                                 837         2   \n",
              "581008             237                                 845         2   \n",
              "581009             241                                 854         2   \n",
              "581010             245                                 864         2   \n",
              "581011             244                                 875         2   \n",
              "\n",
              "       Wilderness_Area  \n",
              "0                    1  \n",
              "1                    1  \n",
              "2                    1  \n",
              "3                    1  \n",
              "4                    1  \n",
              "...                ...  \n",
              "581007               3  \n",
              "581008               3  \n",
              "581009               3  \n",
              "581010               3  \n",
              "581011               3  \n",
              "\n",
              "[581012 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-516a76c1-7cfe-4631-9449-6a65aac6f73e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Soil_Type</th>\n",
              "      <th>Wilderness_Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>232</td>\n",
              "      <td>6279</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>235</td>\n",
              "      <td>6225</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>238</td>\n",
              "      <td>6121</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>6211</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>234</td>\n",
              "      <td>6172</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581007</th>\n",
              "      <td>2396</td>\n",
              "      <td>153</td>\n",
              "      <td>20</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>108</td>\n",
              "      <td>237</td>\n",
              "      <td>837</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581008</th>\n",
              "      <td>2391</td>\n",
              "      <td>152</td>\n",
              "      <td>19</td>\n",
              "      <td>67</td>\n",
              "      <td>12</td>\n",
              "      <td>95</td>\n",
              "      <td>237</td>\n",
              "      <td>845</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581009</th>\n",
              "      <td>2386</td>\n",
              "      <td>159</td>\n",
              "      <td>17</td>\n",
              "      <td>60</td>\n",
              "      <td>7</td>\n",
              "      <td>90</td>\n",
              "      <td>241</td>\n",
              "      <td>854</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581010</th>\n",
              "      <td>2384</td>\n",
              "      <td>170</td>\n",
              "      <td>15</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>245</td>\n",
              "      <td>864</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581011</th>\n",
              "      <td>2383</td>\n",
              "      <td>165</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>244</td>\n",
              "      <td>875</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581012 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-516a76c1-7cfe-4631-9449-6a65aac6f73e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-516a76c1-7cfe-4631-9449-6a65aac6f73e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-516a76c1-7cfe-4631-9449-6a65aac6f73e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forestDF = pd.DataFrame().assign(\n",
        "                Elevation=forestDF['Elevation'], \n",
        "                Horizontal_Distance_To_Fire_Points=forestDF['Horizontal_Distance_To_Fire_Points'],\n",
        "                Soil_Type=forestDF['Soil_Type'],\n",
        "                Horizontal_Distance_To_Roadways=forestDF['Horizontal_Distance_To_Roadways'],\n",
        "                Wilderness_Area=forestDF['Wilderness_Area'], \n",
        "                Horizontal_Distance_To_Hydrology=forestDF['Horizontal_Distance_To_Hydrology'],\n",
        "                Hillshade_Noon=forestDF['Hillshade_Noon'],\n",
        "                Aspect=forestDF['Aspect'],\n",
        "                Slope=forestDF['Slope'],\n",
        "                                                      )\n"
      ],
      "metadata": {
        "id": "2nu7kYPa0WD9"
      },
      "id": "2nu7kYPa0WD9",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign specific features to two different variables\n",
        "if 'Cover_Type' in forestDF:\n",
        "    Y = forestDF['Cover_Type'].values\n",
        "    del forestDF['Cover_Type']\n",
        "    X = forestDF.values"
      ],
      "metadata": {
        "id": "ImGv5F8Tw0uU"
      },
      "id": "ImGv5F8Tw0uU",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-creating logistic regression object\n",
        "lr_clf = LogisticRegression(penalty='l2',C=1.0,class_weight=None)"
      ],
      "metadata": {
        "id": "UX1Oh210w-Oj"
      },
      "id": "UX1Oh210w-Oj",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running logistic regression on 10 random test/train splits\n",
        "iter_num = 0\n",
        "\n",
        "for iter_num, (train_indices,test_indices) in enumerate(cv_object.split(X,Y)):\n",
        "    lr_clf.fit(X[train_indices],Y[train_indices])\n",
        "    y_hat = lr_clf.predict(X[test_indices])\n",
        "    \n",
        "    print('****Iteration',iter_num,'****')\n",
        "    print('Accuracy',mt.accuracy_score(Y[test_indices],y_hat))\n",
        "    print('Confusion Matrix \\n',mt.confusion_matrix(Y[test_indices],y_hat))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeXMjWtRxNif",
        "outputId": "c573d054-495f-47b1-8509-10cc7b43d400"
      },
      "id": "BeXMjWtRxNif",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 0 ****\n",
            "Accuracy 0.5933925974372435\n",
            "Confusion Matrix \n",
            " [[24625 17526   145     0     0     4    41]\n",
            " [12904 43246   496     0     0     7    20]\n",
            " [  306  5609  1059     0     0    42     0]\n",
            " [    1   492    40     0     0     0     0]\n",
            " [  435  1545    16     0     0     0     0]\n",
            " [  282  2905   299     0     0    15     0]\n",
            " [ 3531   601     2     0     0     0     9]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 1 ****\n",
            "Accuracy 0.594709258797105\n",
            "Confusion Matrix \n",
            " [[25282 16954   171     0     0    19    11]\n",
            " [13499 42481   687     0     0    35     2]\n",
            " [  254  5481  1293     0     0   128     0]\n",
            " [    1   496    27     0     0    10     0]\n",
            " [  395  1456    18     0     0     0     0]\n",
            " [  286  2764   372     0     0    47     0]\n",
            " [ 3477   539    14     0     0     0     4]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 2 ****\n",
            "Accuracy 0.595165357176665\n",
            "Confusion Matrix \n",
            " [[25077 17042   257     0     0     4    39]\n",
            " [13126 42626   747     0     0     6    20]\n",
            " [  308  5393  1437     0     0    21     0]\n",
            " [    1   505    44     0     0     0     0]\n",
            " [  405  1447    18     0     0     0     0]\n",
            " [  286  2747   498     0     0     5     0]\n",
            " [ 3551   565    13     0     0     0    15]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 3 ****\n",
            "Accuracy 0.5949157939123775\n",
            "Confusion Matrix \n",
            " [[25340 17005   221     0     0     6    21]\n",
            " [13354 42378   806     0     0    19     8]\n",
            " [  319  5204  1390     0     0    68     0]\n",
            " [    1   486    50     0     0     4     0]\n",
            " [  392  1465    26     0     0     0     0]\n",
            " [  300  2703   438     0     0    10     0]\n",
            " [ 3607   552    17     0     0     0    13]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 4 ****\n",
            "Accuracy 0.5935130762544857\n",
            "Confusion Matrix \n",
            " [[24929 17049   155     0     0     8    60]\n",
            " [13386 42747   680     0     0    35    18]\n",
            " [  273  5565  1227     0     0    98     0]\n",
            " [    2   501    37     0     0     5     0]\n",
            " [  384  1442    11     0     0     0     0]\n",
            " [  258  2740   379     0     0    41     0]\n",
            " [ 3553   584    12     0     0     0    24]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 5 ****\n",
            "Accuracy 0.5943047941963633\n",
            "Confusion Matrix \n",
            " [[24867 17137   245     0     0    29     0]\n",
            " [13230 42764   674     0     0    50     0]\n",
            " [  293  5383  1399     0     0    65     0]\n",
            " [    5   501    55     0     0     4     0]\n",
            " [  425  1528     9     0     0     0     0]\n",
            " [  279  2654   471     0     0    30     0]\n",
            " [ 3481   615    10     0     0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 6 ****\n",
            "Accuracy 0.5937970620379852\n",
            "Confusion Matrix \n",
            " [[24761 17227   181     0     0    18    30]\n",
            " [13069 42940   703     0     0    27    19]\n",
            " [  280  5457  1273     0     0    76     0]\n",
            " [    1   532    45     0     0     6     0]\n",
            " [  370  1458    14     0     0     0     0]\n",
            " [  293  2844   369     0     0    18     0]\n",
            " [ 3558   615    10     0     0     0     9]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Iteration 7 ****\n",
            "Accuracy 0.5908195141261413\n",
            "Confusion Matrix \n",
            " [[24572 17724   185     0     0     0    22]\n",
            " [13024 42829   570     0     0     3    13]\n",
            " [  290  5701  1246     0     0    20     0]\n",
            " [    3   516    31     0     0     0     0]\n",
            " [  395  1514    15     0     0     0     0]\n",
            " [  257  2876   329     0     0     5     0]\n",
            " [ 3479   570    11     0     0     0     3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = cross_val_score(lr_clf, X, y=Y, cv=cv_object) # this also can help with parallelism\n",
        "print(accuracies)"
      ],
      "metadata": {
        "id": "dZGNJkgvxTRS"
      },
      "id": "dZGNJkgvxTRS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Advantages 10\n",
        "Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
      ],
      "metadata": {
        "id": "ZDkhl8Y-h3f_"
      },
      "id": "ZDkhl8Y-h3f_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpret Feature Importance 30\n",
        "\n",
        "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
      ],
      "metadata": {
        "id": "5M-XYvRzh_Id"
      },
      "id": "5M-XYvRzh_Id"
    },
    {
      "cell_type": "markdown",
      "id": "a558f61e",
      "metadata": {
        "id": "a558f61e"
      },
      "source": [
        "## Looking at weights of the complex model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f74ab89",
      "metadata": {
        "id": "7f74ab89"
      },
      "outputs": [],
      "source": [
        "weights = lr_clf.coef_.T\n",
        "varNames = forestDF.columns\n",
        "for coef, name in zip(weights,varNames):\n",
        "    print(name,'has weight of',coef[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0868f669",
      "metadata": {
        "id": "0868f669"
      },
      "source": [
        "### Scaling the weights for interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62176a55",
      "metadata": {
        "id": "62176a55"
      },
      "outputs": [],
      "source": [
        "sclObj = StandardScaler()\n",
        "sclObj.fit(X[train_indices])\n",
        "\n",
        "X_trainScaled = sclObj.transform(X[train_indices])\n",
        "x_testScaled = sclObj.transform(X[test_indices])\n",
        "\n",
        "lrs_clf = LogisticRegression(penalty='l2',C=0.05)\n",
        "lrs_clf.fit(X_trainScaled,Y[train_indices])\n",
        "\n",
        "y_hatS = lrs_clf.predict(x_testScaled)\n",
        "\n",
        "acc = mt.accuracy_score(Y[test_indices],y_hatS)\n",
        "conf = mt.confusion_matrix(Y[test_indices],y_hatS)\n",
        "print('accuracy:',acc)\n",
        "print(conf)\n",
        "\n",
        "zipVars = zip(lrs_clf.coef_.T,forestDF.columns)\n",
        "zipVars = sorted(zipVars)\n",
        "\n",
        "for coef, name in zipVars:\n",
        "    print(name,'has weight of', coef[0])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab1b855",
      "metadata": {
        "id": "fab1b855"
      },
      "source": [
        "### Plotting weights (scaled weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612c25d6",
      "metadata": {
        "id": "612c25d6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "weights = pd.Series(lrs_clf.coef_[0],index=forestDF.columns)\n",
        "weights.plot(kind='bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49c6293",
      "metadata": {
        "id": "e49c6293"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f16474f",
      "metadata": {
        "id": "6f16474f"
      },
      "source": [
        "### Creating and running the SVM using the scaled and split sets from earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpret Support Vectors(10)\n",
        "\n",
        "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model— then analyze the support vectors from the subsampled dataset."
      ],
      "metadata": {
        "id": "IeTkwGHYiUyW"
      },
      "id": "IeTkwGHYiUyW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffcba57",
      "metadata": {
        "id": "2ffcba57"
      },
      "outputs": [],
      "source": [
        "##SVM\n",
        "\n",
        "for train_indices, test_indices in cv_object.split(X,Y): \n",
        "    # I will create new variables here so that it is more obvious what \n",
        "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
        "    # but it makes this code less readable)\n",
        "    X_train = X[train_indices]\n",
        "    y_train = Y[train_indices]\n",
        "    \n",
        "    X_test = X[test_indices]\n",
        "    y_test = Y[test_indices]\n",
        "\n",
        "X_train_scaled = sclObj.transform(X_train) # apply to training\n",
        "X_test_scaled = sclObj.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets investigate SVMs on the data and play with the parameters and kernels\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# train the model just as before\n",
        "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
        "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
        "\n",
        "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
        "\n",
        "acc = mt.accuracy_score(y_test,y_hat)\n",
        "conf = mt.confusion_matrix(y_test,y_hat)\n",
        "print('accuracy:', acc )\n",
        "print(conf)"
      ],
      "metadata": {
        "id": "xPxkd8s-HT_P"
      },
      "id": "xPxkd8s-HT_P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *below here isn't yet edited to work, but pulls from example notebook for how to interpret the support vector (like he mentioned we should do in class)*"
      ],
      "metadata": {
        "id": "1hd1rNLFici4"
      },
      "id": "1hd1rNLFici4"
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets see the statistics of these attributes\n",
        "from pandas.plotting import boxplot\n",
        "\n",
        "# group the original data and the support vectors\n",
        "df_grouped_support = forest_cover_type.groupby(['Cover_Type'])\n",
        "df_grouped = forest_cover_type.groupby(['Cover_Type'])\n",
        "\n",
        "# plot KDE of Different variables\n",
        "vars_to_plot = ['Age','Pclass','IsMale','FamilySize']\n",
        "\n",
        "for v in vars_to_plot:\n",
        "    plt.figure(figsize=(10,4))\n",
        "    # plot support vector stats\n",
        "    plt.subplot(1,2,1)\n",
        "    ax = df_grouped_support[v].plot.kde() \n",
        "    plt.legend(['Perished','Survived'])\n",
        "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
        "    \n",
        "    # plot original distributions\n",
        "    plt.subplot(1,2,2)\n",
        "    ax = df_grouped[v].plot.kde() \n",
        "    plt.legend(['Perished','Survived'])\n",
        "    plt.title(v+' (Original)')"
      ],
      "metadata": {
        "id": "zHA-KLY0ga-f"
      },
      "id": "zHA-KLY0ga-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
        "\n",
        "# now lets look at the support for the vectors and see if we they are indicative of anything\n",
        "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
        "\n",
        "# make a dataframe of the training data\n",
        "df_tested_on = df_imputed.iloc[train_indices].copy() # saved from above, the indices chosen for training\n",
        "# now get the support vectors from the trained model\n",
        "df_support = df_tested_on.iloc[svm_clf.support_,:].copy()\n",
        "\n",
        "df_support['Survived'] = y[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
        "df_imputed['Survived'] = y # also add it back in for the original data\n",
        "df_support.info()"
      ],
      "metadata": {
        "id": "DAURr5CDgeza"
      },
      "id": "DAURr5CDgeza",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}